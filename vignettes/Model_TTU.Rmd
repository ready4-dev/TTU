---
title: "Model Transfer to Utility"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Model Transfer to Utility}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r message=FALSE, warning=FALSE}
library(TTU)
```

## Set-up workspace 
To facilitate reproducibility, we begin by setting a seed.

```{r}
seed_1L_int = 12345
set.seed(seed_1L_int)
```

We next create a directory in which we will write all output.

```{r warning = F}
path_to_write_to_1L_chr <- "Output" 
dir.create(path_to_write_to_1L_chr)
```

## Import and describe data
As this is an illustrative example, our input data does not actually exist. So we are going to have to create a fake dataset.

```{r message=FALSE}
data_tb <- readRDS(url("https://dataverse.harvard.edu/api/access/datafile/4750597"))
```

The dataset we are using has `r nrow(data_tb)` records on `r length(data_tb$uid %>% unique())` study participants. The first six records are reproduced below.

```{r inputds, eval = knitr::is_html_output(), results='asis'}
data_tb %>%
    head() %>%
  ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Input dataset",
                          mkdn_tbl_ref_1L_chr = "tab:inputds")
```

We next create a lookup table summarising key information about the variables from our dataset that we will explore as candidate predictors in our models. The predictors lookup table must be of the `TTU_predictors_lup` class.

```{r}
predictors_lup <- TTU_predictors_lup(make_pt_TTU_predictors_lup(short_name_chr = c("k10_int","psych_well_int"),
                                              long_name_chr = c("Kessler Psychological Distress - 10 Item Total Score",
                                                   "Overall Wellbeing Measure (Winefield et al. 2012)"),
                                              min_val_dbl = c(10,18),
                                              max_val_dbl = c(50,90),
                                              class_chr = "integer",
                                              increment_dbl = 1,
                                              class_fn_chr = "as.integer",
                                              mdl_scaling_dbl = 0.01,
                                              covariate_lgl = F))
```

We also require a data dictionary for our input dataset. The dictionary must be of the `ready4use::ready4_dictionary` class. In the example below we are adapting an existing dictionary (generated by a call to the `youthvars::make_tfd_repln_ds_dict_r3` function) by dropping unnecessary entries and adding a number of additional records to it.

```{r}
dictionary_tb <- make_eq5d_ds_dict(data_tb,
                                   predictors_lup = predictors_lup)
```

## Score utility and summarise meta-data
We now convert study participant responses to the EQ-5D questionnaire to health utility scores. We do this using the `eq5d` package.

```{r message=FALSE, results='hide', warning=FALSE}
library(eq5d)
data_tb <- data_tb %>% 
        dplyr::rename_with(~stringr::str_replace(.x,"eq5dq_",""),dplyr::starts_with("eq5dq_")) %>%
  dplyr::mutate(`:=`(EQ5D_total_dbl, 
                     eq5d::eq5d(., country="UK", version = "5L", type = "CW"))) %>%
    dplyr::rename_with(~paste0("eq5dq_",.x),c("MO","SC","UA","PD","AD"))
```

We can label dataset variables using descriptions from the data dictionary.

```{r}
data_tb <- data_tb %>%
  ready4use::add_labels_from_dictionary(dictionary_tb = dictionary_tb,
                                        remove_old_lbls_1L_lgl = T) 
```

The first six records of the scored and labelled dataset are reproduced below.

```{r scoredds, eval = knitr::is_html_output(), results='asis'}
data_tb %>%
    head() %>%
  ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Scored and labelled dataset",
                          use_lbls_as_col_nms_1L_lgl = T,
                          mkdn_tbl_ref_1L_chr = "tab:scoredds")
```

We next create an object `ds_smry_ls` to store a description of some structural properties of the dataset such as:

 - the name of the dependent variable (ie total health utility score);
 - the names of the variables we will be exploring as candidate predictors and as candidate covariates in our modelling;
 - the candidate predictors look-up table that we previously created;
 - the names of the variables for unique participant identifier and data collection round; and
 - the value of the data collection round variable for the baseline timepoint.

```{r}
ds_smry_ls <- make_ds_smry_ls(candidate_predrs_chr = predictors_lup$short_name_chr,
                              candidate_covar_nms_chr = c("d_sex_birth_s", "d_age",  "d_sexual_ori_s", "d_relation_s", "d_studying_working"),
                              depnt_var_nm_1L_chr = "EQ5D_total_dbl",
                              id_var_nm_1L_chr = "uid",
                              round_var_nm_1L_chr = "Timepoint",
                              round_bl_val_1L_chr = "BL",
                              predictors_lup = predictors_lup)
```

## Test candidate models, predictors and covariates
Our first analytic task is to test which models, predictors and covariates perform best. This tasks can be broken down into the following steps.

### Preliminary tasks
We begin by reviewing the `TTU` packages lookup table of types of models we can test.

```{r}
data("mdl_types_lup",package = "TTU") 
mdl_types_lup %>%
    ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Model types lookup table")
```

We modify this table as appropriate (in the below example, we adjust the start values for two of the models, as the default values are not appropriate for our data). We then add the lookup table to a new object, `mdl_smry_ls` which stores information about the candidate models we will be using. 

```{r}
mdl_smry_ls <- TTU::mdl_types_lup %>%
  dplyr::mutate(start_chr = dplyr::case_when(short_name_chr %in% c("GLM_BNL_LGT","GLM_BNL_CLL") ~ c("0.5, -0.05"),
                                             T ~ start_chr)) %>%
  make_mdl_smry_ls()
```

For the initial set of tests on candidate models, we just need data from one timepoint as we are not exploring longitudinal change at this stage. We also only need data on the candidate predictors and total utility score. so can slim down our dataset to these parameters.

```{r}
bl_tb <- youthvars::transform_ds_for_tstng(data_tb, 
                                           depnt_var_nm_1L_chr = ds_smry_ls$depnt_var_nm_1L_chr,
                                           candidate_predrs_chr = ds_smry_ls$candidate_predrs_chr,
                                           dep_var_max_val_1L_dbl = 0.999,
                                           round_var_nm_1L_chr = ds_smry_ls$round_var_nm_1L_chr, 
                                           round_val_1L_chr = ds_smry_ls$round_bl_val_1L_chr)
 
```

The first six records of the slimmed down dataset are as follows.

```{r}
bl_tb %>%
  head() %>%
    ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Slimmed down prediction dataset")
  
```

### Identify most highly correlated candidate predictor
By exploring correlations in the slimmed down dataset, we can reorder our vector of candidate predictors to reflect the descending order of correlation with the dependent variable. 

```{r}
ds_smry_ls$candidate_predrs_chr <- reorder_cndt_predrs_chr(ds_smry_ls$candidate_predrs_chr,
        data_tb = bl_tb, depnt_var_nm_1L_chr = ds_smry_ls$depnt_var_nm_1L_chr)
```

Based on this reordering, we can specify the the candidate predictor with the highest correlation with our utility variable, adding its description and allowed potential values to `mdl_smry_ls`.

```{r}
mdl_smry_ls <- add_prefd_predr_var_to_mdl_smry_ls(mdl_smry_ls,
                                                  ds_smry_ls = ds_smry_ls)
```

### Test all candidate models using most correlated predictor
We now compare all candidate model types, each using only the highest correlated candidate predictor. 

```{r warning = FALSE, message=FALSE}
mdl_smry_ls$smry_of_sngl_predr_mdls_tb <- write_sngl_predr_multi_mdls_outps(data_tb = bl_tb,
        folds_1L_int = mdl_smry_ls$folds_1L_int, mdl_types_chr = mdl_smry_ls$mdl_types_chr,
        depnt_var_nm_1L_chr = ds_smry_ls$depnt_var_nm_1L_chr, predr_var_nm_1L_chr = mdl_smry_ls$predr_var_nm_1L_chr,
        predr_var_desc_1L_chr = mdl_smry_ls$predr_var_desc_1L_chr, 
        predr_vals_dbl = mdl_smry_ls$predr_vals_dbl,
        path_to_write_to_1L_chr = path_to_write_to_1L_chr, new_dir_nm_1L_chr =  "A_Candidate_Mdls_Cmprsn",
        start_1L_chr = NA_character_,
        mdl_types_lup = mdl_smry_ls$mdl_types_lup,
        dictionary_tb = dictionary_tb) 
```

The `write_sngl_predr_multi_mdls_outps` function will write each model to be tested to a new sub-directory of "`r path_to_write_to_1L_chr`" called "A_Candidate_Mdls_Cmprsn". Also written to that sub-directory are a number of plots for each model. 

The `write_sngl_predr_multi_mdls_outps` function also outputs a table summarising the performance of each of the candidate models.

```{r mdl_cmprsn, eval = knitr::is_html_output(), results='asis'}
mdl_smry_ls$smry_of_sngl_predr_mdls_tb %>%
  ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Comparison of model types for highest correlated predictor using baseline data",
                          mkdn_tbl_ref_1L_chr = "tab:mdl_cmprsn")
```

We can now identify the highest performing model in each category of candidate model based on the testing R^2^ statistic (RsquaredP in the previous table).

```{r message=FALSE}
mdl_smry_ls$prefd_mdl_types_chr <- make_prefd_mdls_vec(mdl_smry_ls$smry_of_sngl_predr_mdls_tb,
                                           choose_from_pfx_chr = mdl_smry_ls$choose_from_pfx_chr)
```

```{r}
mdl_smry_ls$prefd_mdl_types_chr
```
We can override these automated selections and instead incorporate other considerations (possibly based on judgments informed by visual inspection of the plots and the desirability of constraining predictions to a maximum value of one). We do this in the following command, specifying new preferred model types, in descending order of preference.

```{r}
mdl_smry_ls$prefd_mdl_types_chr <- c("OLS_NTF", "GLM_BNL_CLL", "BET_LGT")
```

### Compare all candidate predictors using most preferred model
We can now compare all of our candidate single predictors using the most preferred model type.

```{r message=FALSE, results='hide'}
mdl_smry_ls$max_nbr_of_boruta_mdl_runs_int = 300L
mdl_smry_ls$predr_cmprsn_tb <- write_predr_cmprsn_outps(data_tb = bl_tb,
                                             path_to_write_to_1L_chr = path_to_write_to_1L_chr,
                                             new_dir_nm_1L_chr = "B_Candidate_Predrs_Cmprsn",
                                             depnt_var_nm_1L_chr = ds_smry_ls$depnt_var_nm_1L_chr, 
                                             candidate_predrs_chr = ds_smry_ls$candidate_predrs_chr,
                                             max_nbr_of_boruta_mdl_runs_int = mdl_smry_ls$max_nbr_of_boruta_mdl_runs_int)
```

The previous call to the `write_predr_cmprsn_outps`{.R} function saved the tested models along with model plots in the "B_Candidate_Predrs_Cmprsn" sub-directory of "Output".

These results are also viewable as a table.

```{r}
mdl_smry_ls$predr_cmprsn_tb %>%
    ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Comparison of all candidate predictors using preferred model")
```

### Compare single predictor model performance across all candidate predictors
Now, we compare the performance of single predictor models of our preferred model type (in our case, a `r mdl_smry_ls$mdl_types_lup %>% ready4fun::get_from_lup_obj(target_var_nm_1L_chr = "long_name_chr",match_value_xx = mdl_smry_ls$prefd_mdl_types_chr[1], match_var_nm_1L_chr = "short_name_chr", evaluate_lgl = F)`) for each candidate predictor.

```{r message=FALSE, warning=F}
    mdl_smry_ls$smry_of_mdl_sngl_predrs_tb <- write_mdl_type_multi_outps(data_tb = bl_tb,
        folds_1L_int = mdl_smry_ls$folds_1L_int, predrs_var_nms_chr = mdl_smry_ls$predr_cmprsn_tb$predr_chr, start_1L_chr = NA_character_,
        mdl_type_1L_chr = mdl_smry_ls$prefd_mdl_types_chr[1], depnt_var_nm_1L_chr = ds_smry_ls$depnt_var_nm_1L_chr,
        path_to_write_to_1L_chr = path_to_write_to_1L_chr, new_dir_nm_1L_chr = "C_Predrs_Sngl_Mdl_Cmprsn",
        fl_nm_pfx_1L_chr = "C_PREDR", mdl_types_lup = mdl_smry_ls$mdl_types_lup) 
```

The previous call to the `write_mdl_type_multi_outps`{.R} function saves the tested models along with the two plots for each model in the "C_Predrs_Sngl_Mdl_Cmprsn" sub-directory of "Output". 

The performance of each single predictor model can also be summarised in a table.

```{r}
mdl_smry_ls$smry_of_mdl_sngl_predrs_tb %>%
    ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Preferred single predictor model performance by candidate predictor")
```

### Compare candidate covariates
We rerun each of the models from the previous step, but this time add all our candidate covariates to each model. 

```{r}
bl_tb <- data_tb %>% youthvars::transform_ds_for_tstng(depnt_var_nm_1L_chr = ds_smry_ls$depnt_var_nm_1L_chr,candidate_predrs_chr = ds_smry_ls$candidate_predrs_chr,
        covar_var_nms_chr = ds_smry_ls$candidate_covar_nms_chr, remove_all_msng_1L_lgl = T, round_var_nm_1L_chr = ds_smry_ls$round_var_nm_1L_chr,
        round_val_1L_chr = ds_smry_ls$round_bl_val_1L_chr)
mdl_smry_ls$mdls_with_covars_smry_tb <- write_mdl_type_covars_mdls(bl_tb,
        depnt_var_nm_1L_chr = ds_smry_ls$depnt_var_nm_1L_chr, predrs_var_nms_chr = ds_smry_ls$candidate_predrs_chr,
        covar_var_nms_chr = ds_smry_ls$candidate_covar_nms_chr, mdl_type_1L_chr = mdl_smry_ls$prefd_mdl_types_chr[1],
        path_to_write_to_1L_chr = path_to_write_to_1L_chr, new_dir_nm_1L_chr = "D_Predr_Covars_Cmprsn",
        fl_nm_pfx_1L_chr = "D_CT",
        mdl_types_lup = mdl_smry_ls$mdl_types_lup, start_1L_chr = NA_character_)
```

The updated models are saved to the "D_Predr_Covars_Cmprsn" subdirectory of "Output" and we can summarise the performance of each of the updated models, along with all model terms, in a table.

```{r}
mdl_smry_ls$mdls_with_covars_smry_tb %>%
    ready4show::print_table(output_type_1L_chr = "HTML",
                            caption_1L_chr = "Preferred performance of models with covariate predictors by candidate predictor", 
                          use_lbls_as_col_nms_1L_lgl = T)
```

We can now identify which, if any, of the candidate covariates we previously specified are significant predictors in any of the models.

```{r}
mdl_smry_ls$signt_covars_chr <- get_signft_covars(mdls_with_covars_smry_tb = mdl_smry_ls$mdls_with_covars_smry_tb,
                                      covar_var_nms_chr = ds_smry_ls$candidate_covar_nms_chr) 
```
```{r}
mdl_smry_ls$signt_covars_chr
```
We can override the covariates to select, potentially because we want to select only covariates that are significant for all or most of the models. However, in the below example we have opted not to do so and continue to use `r ifelse(is.na(mdl_smry_ls$signt_covars_chr),"no covariates",paste0(mdl_smry_ls$signt_covars_chr, collapse = "and "))` as selected by the algorithm in the previous step.

```{r}
mdl_smry_ls$prefd_covars_chr <- NA_character_
    if (!is.na(mdl_smry_ls$prefd_covars_chr))
        mdl_smry_ls$prefd_covars_chr <- mdl_smry_ls$signt_covars_chr
```

### Test preferred model with preferred covariates for each candidate predictor
We now conclude our model testing by rerunning the previous step, except confining our covariates to those we prefer.

```{r warning = F, message=F}
    empty_tb <- write_mdl_type_multi_outps(data_tb = bl_tb, folds_1L_int = NULL,
        start_1L_chr = NA_character_, predrs_var_nms_chr = mdl_smry_ls$predr_cmprsn_tb$predr_chr,
        covar_var_nms_chr = mdl_smry_ls$prefd_covars_chr, mdl_type_1L_chr = mdl_smry_ls$prefd_mdl_types_chr[1],
        depnt_var_nm_1L_chr = ds_smry_ls$depnt_var_nm_1L_chr, path_to_write_to_1L_chr = path_to_write_to_1L_chr,
        new_dir_nm_1L_chr = "E_Predrs_W_Covars_Sngl_Mdl_Cmprsn", mdl_types_lup = mdl_smry_ls$mdl_types_lup, fl_nm_pfx_1L_chr = "E_CK_CV")
```

The previous call to the `write_mdl_type_multi_outps`{.R} function saves the tested models along with the two plots for each model in the "E_Predrs_W_Covars_Sngl_Mdl_Cmprsn" sub-directory of "Output". 


## Apply preferred model types and predictors to time series data
The next main step is to use the preferred model types and covariates identified from the preceding analysis of cross-sectional data in time series analysis. 

### Preliminary steps
First we summarise the combinations of model types, candidate predictors and covariates that we will be using.

```{r}
    mdl_smry_ls$predr_vars_nms_ls <- make_predr_vars_nms_ls(main_predrs_chr = mdl_smry_ls$predr_cmprsn_tb$predr_chr,
        covars_ls = list(mdl_smry_ls$prefd_covars_chr))
```

```{r}
mdl_smry_ls$mdl_nms_ls <- make_mdl_nms_ls(mdl_smry_ls$predr_vars_nms_ls, mdl_types_chr = mdl_smry_ls$prefd_mdl_types_chr)
```

```{r}
mdl_smry_ls$mdl_nms_ls %>% purrr::flatten_chr()
```

We now create a composite object `outp_smry_ls` that contains the key input and output data used in testing models, predictors and covariates that we will need for the time series modelling.

```{r}
outp_smry_ls <- list(scored_data_tb = data_tb, 
                     smry_of_sngl_predr_mdls_tb = mdl_smry_ls$smry_of_sngl_predr_mdls_tb,
                     prefd_mdl_types_chr = mdl_smry_ls$prefd_mdl_types_chr, 
                     predr_cmprsn_tb = mdl_smry_ls$predr_cmprsn_tb,
                     smry_of_mdl_sngl_predrs_tb = mdl_smry_ls$smry_of_mdl_sngl_predrs_tb,
                     mdls_with_covars_smry_tb = mdl_smry_ls$mdls_with_covars_smry_tb,
                     signt_covars_chr = mdl_smry_ls$signt_covars_chr, 
                     prefd_covars_chr = mdl_smry_ls$prefd_covars_chr,
                     depnt_var_nm_1L_chr = ds_smry_ls$depnt_var_nm_1L_chr, 
                     predr_vars_nms_ls = mdl_smry_ls$predr_vars_nms_ls,
                     mdl_nms_ls = mdl_smry_ls$mdl_nms_ls, 
                     id_var_nm_1L_chr = ds_smry_ls$id_var_nm_1L_chr,
                     round_var_nm_1L_chr = ds_smry_ls$round_var_nm_1L_chr,
                     round_bl_val_1L_chr = ds_smry_ls$round_bl_val_1L_chr,
                     path_to_write_to_1L_chr = path_to_write_to_1L_chr, 
                     seed_1L_int = seed_1L_int,
                     folds_1L_int = mdl_smry_ls$folds_1L_int, 
                     max_nbr_of_boruta_mdl_runs_int = mdl_smry_ls$max_nbr_of_boruta_mdl_runs_int,
                     mdl_types_lup = mdl_smry_ls$mdl_types_lup, 
                     file_paths_chr = list.files(path_to_write_to_1L_chr, recursive = T))
```

### Time series modelling
Next we test each of the `r length(mdl_smry_ls$mdl_nms_ls %>% purrr::flatten_chr())` time series models we specified in the previous step. Note the current version of the `write_ts_mdls_from_alg_outp` function only works with the two model types that we recommend for TTU modelling: 

- `r mdl_smry_ls$mdl_types_lup %>% ready4fun::get_from_lup_obj(target_var_nm_1L_chr = "long_name_chr",match_value_xx = mdl_smry_ls$prefd_mdl_types_chr[1], match_var_nm_1L_chr = "short_name_chr", evaluate_lgl = F)`
- `r mdl_smry_ls$mdl_types_lup %>% ready4fun::get_from_lup_obj(target_var_nm_1L_chr = "long_name_chr",match_value_xx = mdl_smry_ls$prefd_mdl_types_chr[2], match_var_nm_1L_chr = "short_name_chr", evaluate_lgl = F)`

However, as there is some potential utility in allowing users to explore less suitable model types, we may address this limitation in future releases of TTU.

Note, that in many cases both the `prior_ls` and `control_ls` arguments can be set to `NULL` (which may speed up execution). However, in this example doing so would result in warning messages suggesting a change to the adapt_delta control value (default = 0.8). We have therefore passed a value to the `control_ls` argument that addresses this issue.

```{r eval = F}
outp_smry_ls <- write_ts_mdls_from_alg_outp(outp_smry_ls,
                                            fn_ls = list(fit_gsn_log_lnk,fit_clg_log_tfmn),
                                            predictors_lup = predictors_lup ,
                                            backend_1L_chr = "cmdstanr",
                                            new_dir_nm_1L_chr = "F_TS_Mdls",
                                            iters_1L_int = 4000L,
                                            prior_ls = NULL, 
                                            control_ls = list(adapt_delta = 0.99))
```

The `write_ts_mdls_from_alg_outp`{.R} function writes the models it tests to the "F_TS_Mdls" sub-directory of "Output" along with three plots for each model. 

### Sharing models
The raw models outputted by `write_ts_mdls_from_alg_outp`{.R} are not suitable for sharing as they both may contain confidential data and are very large in file size. An additional step is required to create shareable versions that are of more modest file size and have the source dataset replaced with synthetic data, but that are otherwise identical to the original models. 

As we are not sharing the output of this example in an online data repository, we set the `dv_ls` element of the `outp_smry_ls` object to NULL. 

```{r eval=FALSE}
outp_smry_ls$dv_ls <- NULL
```

This following call to `write_shareable_mdls`{.R} writes shareable models to a new subdirectory (G_Shareable) of "Output". 

```{r eval=F}
outp_smry_ls <- write_shareable_mdls(outp_smry_ls,
                                     new_dir_nm_1L_chr = "G_Shareable")
```

## Create shareable population data

To aid replication, we can create a purely synthetic dataset, representative of the source data, but containing no real data on any individual. The `make_fake_ts_data`{.R} function uses the `syn`{.R} function from the `synthpop` package to perform this task.

```{r eval=T}
outp_smry_ls$fk_data_tb <- TTU::make_fake_ts_data(outp_smry_ls)
```

The first six records from the replication dataset are reproduced below. Note that the "change" variables are scaled by the factor we specified in the `ds_smry_ls$predictors_lup` predictors lookup table.

```{r}
outp_smry_ls$fk_data_tb %>%
  head() %>%
    ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Synthetic dataset",
                          scroll_box_args_ls = list(width = "100%"))
```

## Purge dataset copies
Because the files created in analysis are large, multiple objects containing copies of the source dataset have been saved to our output directory during the analysis process. We therefore need to delete all of these copies.

```{r eval=F}
write_to_delete_mdl_fls(outp_smry_ls)
outp_smry_ls$scored_data_tb <- NULL
```

## Save work

Finally, we can save a complete record of our analysis.

```{r eval=F}
saveRDS(outp_smry_ls,paste0(outp_smry_ls$path_to_write_to_1L_chr,"/I_ALL_OUTPUT_.RDS"))
```
