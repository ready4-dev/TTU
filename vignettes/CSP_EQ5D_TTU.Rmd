---
title: "Complete Study Program - Transfer To EQ5D Health Utility For A Community Sample"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Analyse, report and share}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
\blandscape
<!---BLOCK_LANDSCAPE_START--->

```{r echo = TRUE }
library(magrittr)
```

# Input parameters

## Reporting parameters
```{, child=c('_Reporting_Params.Rmd')}
```

## Data parameters

### Dataset
As this is an illustrative example, we first must create a fake dataset (if using real data, skip this step).

```{r message=FALSE}
ds_tb <- readRDS(url("https://dataverse.harvard.edu/api/access/datafile/4750597")) 
```
```{r inputds, eval = knitr::is_html_output(), results='asis'}
ds_tb %>%
    head() %>%
  ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Input dataset",
                          mkdn_tbl_ref_1L_chr = "tab:inputds")
```

We note our use of synthetic data by creating an object `use_fake_data_1L_lgl` and setting it to `TRUE`. For real world application - set this variable to `FALSE`.

```{r }
use_fake_data_1L_lgl <-  TRUE
```

### Data dictionary
A data dictionary must also be supplied for the dataset. The dictionary must be of class `ready4_dictionary` from the `ready4use` package.

```{r}
dictionary_tb <- TTU::make_eq5d_ds_dict(ds_tb) 
```
```{r dictionary, eval = knitr::is_html_output(), results='asis'}
dictionary_tb %>%
  ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Data dictionary",
                          mkdn_tbl_ref_1L_chr = "tab:dictionary")
```

### Dataset metadata
We describe the features of our dataset that are most relevant to the analyses we are planning to undertake. Note all, Multi-Attribute Utility Instrument (MAUI) question variables must start with a common prefix, which needs to be passed to the `maui_item_pfx_1L_chr` argument. The dataset does not need to include variables for total health utility scores (weighted and unweighted), as these variables will be computed during the analysis. However, you can supply the names you wish assigned to these variables once they are computed using the `utl_wtd_var_nm_1L_chr` and `utl_unwtd_var_nm_1L_chr` arguments.

```{r echo = TRUE}
ds_descvs_ls <- TTU::make_ds_descvs_ls(candidate_predrs_chr = c("k10_int","psych_well_int"),#
                     cohort_descv_var_nms_chr = c("d_age", "Gender", "d_relation_s","d_sexual_ori_s", "Region", "CALD", "d_studying_working"),
                     dictionary_tb = dictionary_tb, 
                     id_var_nm_1L_chr = "uid", 
                     msrmnt_date_var_nm_1L_chr = "data_collection_dtm",
                     round_var_nm_1L_chr = "Timepoint", 
                     round_vals_chr = c("BL", "FUP"),
                     maui_item_pfx_1L_chr = "eq5dq_", 
                     utl_wtd_var_nm_1L_chr = "EQ5D_total_dbl", 
                     utl_unwtd_var_nm_1L_chr = "EQ5d_cumulative_dbl")
```

### Candidate predictors metadata
We create a lookup table with metadata on the dataset variables that we will be exploring as candidate predictors.

```{r}
predictors_lup <- TTU::TTU_predictors_lup(TTU::make_pt_TTU_predictors_lup(short_name_chr = ds_descvs_ls$candidate_predrs_chr,
                                              long_name_chr = c("Kessler Psychological Distress - 10 Item Total Score",
                                                   "Overall Wellbeing Measure (Winefield et al. 2012)"),
                                              min_val_dbl = c(10,18),
                                              max_val_dbl = c(50,90),
                                              class_chr = "integer",
                                              increment_dbl = 1,
                                              class_fn_chr = "as.integer",
                                              mdl_scaling_dbl = 0.01,
                                              covariate_lgl = F))
```

## Analysis parameters

### Multi-Attribute Utility Instrument (MAUI) parameters
We also need to provide information specific to the MAUI used to collect the data from which health utility will be derived. If our source dataset does not include a pre-calculated weighted utility variable, we must supply a function to calculate this variable using the `maui_scoring_fn` argument. Note if specifying such a function, it must:
 - include identical arguments as in the below example (including names and order), even if all arguments are not required; and
 - also calculate an unweighted score that is a simple sum of all maui item question responses (e.g. the last three lines of the example `maui_scoring_fn`).

```{r}
maui_params_ls <- TTU::make_maui_params_ls(maui_itm_short_nms_chr = c("Mobility", "Self-care", "Activities","Pain","Anxiety"),
                                      maui_scoring_fn = function(data_tb,
                                             maui_item_pfx_1L_chr,
                                             id_var_nm_1L_chr, 
                                             utl_wtd_var_nm_1L_chr,
                                             utl_unwtd_var_nm_1L_chr){
                    require(eq5d)
                    data_tb %>% 
                      dplyr::rename_with(~stringr::str_replace(.x,maui_item_pfx_1L_chr,""),
                                         dplyr::starts_with(maui_item_pfx_1L_chr)) %>%
                      dplyr::mutate(`:=`(!!rlang::sym(utl_wtd_var_nm_1L_chr), 
                                         eq5d::eq5d(., country="UK", version = "5L", type = "CW"))) %>%
                      dplyr::rename_with(~paste0(maui_item_pfx_1L_chr,.x),c("MO","SC","UA","PD","AD")) %>%
                      dplyr::mutate(`:=`(!!rlang::sym(utl_unwtd_var_nm_1L_chr),                                          rowSums(dplyr::across(dplyr::starts_with(maui_item_pfx_1L_chr))))) %>%
                      dplyr::filter(!is.na(!!rlang::sym(utl_unwtd_var_nm_1L_chr)))
                    },
                    utl_min_val_1L_dbl = 0.03)
```

## Candidate model types
We next create a lookup table of the candidate model types we wish to explore. A template look-up table is available as part of the `TTU` package, but this may need need to be adapted for optimal use with your input data.

```{r}
mdl_types_lup <- TTU::get_cndts_for_mxd_mdls() 
```

```{r mdltypeslup, eval = knitr::is_html_output(), results='asis'}
mdl_types_lup %>%
  ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Candidate model types lookup table",
                          mkdn_tbl_ref_1L_chr = "tab:mdltypeslup")
```

We combine our candidate model types lookup table with parameters specific to the analyses to be run to compare the performance of each model.

```{r}
mdl_smry_ls <- TTU::make_mdl_smry_ls(mdl_types_lup = mdl_types_lup,
                                     folds_1L_int = 10L,
                                     max_nbr_of_boruta_mdl_runs_int = 300L)
```

We create a summary object that contains the core parameters that will be common to most of the analyses we are planning to run.

```{r echo = TRUE }
analysis_core_params_ls <- TTU::make_analysis_core_params_ls(ds_descvs_ls = ds_descvs_ls,
                                                             mdl_smry_ls = mdl_smry_ls,
                                                             output_format_ls = output_format_ls,
                                                             predictors_lup = predictors_lup,
                                                             use_fake_data_1L_lgl = use_fake_data_1L_lgl,
                                                             control_ls = list(adapt_delta = 0.95))
```

## Path parameters
We next create an object that specifies the relative locations of the input data and the intended destination for analysis outputs and reports. The default settings of the `make_path_params_ls` function will write all output into a new directory, created one level up from the current working directory.

```{r}
path_params_ls <- TTU::make_path_params_ls("fake_data.rds")
```
```{r echo = TRUE }
path_params_ls$paths_ls <- TTU::write_main_oupt_dir(path_params_ls, 
                                     use_fake_data_1L_lgl = use_fake_data_1L_lgl)
```
## Output repositories
We provide details of dataverse dataset(s) to which results will be posted. If you do not permissions for a dataverse dataset to write to, use `dv_ls <- NULL`.

```{r echo = TRUE }
dv_ls <- list(primary_dv_chr = c("fakes","https://doi.org/10.7910/DVN/612HDC"))
```

# Primary Analysis

## Consolidate required parameters
```{r}
valid_params_ls_ls <- TTU::make_valid_params_ls_ls(analysis_core_params_ls,
                                                   candidate_covar_nms_chr = c("d_sex_birth_s", "d_age",  "d_sexual_ori_s", "d_relation_s", "d_studying_working"),
                                                   ds_tb = ds_tb, 
                                                   path_params_ls = path_params_ls,
                                                   maui_params_ls = maui_params_ls)
```

## Run analysis

```{r echo = TRUE}
TTU::write_report(params_ls = valid_params_ls_ls$params_ls,
                  paths_ls = path_params_ls$paths_ls,
                  rprt_nm_1L_chr = "Main_Analysis_Rprt",
                  abstract_args_ls = NULL,
                  header_yaml_args_ls = header_yaml_args_ls)
```

## Report results

```{r echo = TRUE }
TTU::write_mdl_smry_rprt(header_yaml_args_ls,
                         path_params_ls = path_params_ls,
                         use_fake_data_1L_lgl = use_fake_data_1L_lgl,
                         output_format_ls = output_format_ls)
```

## Share (de-confidentialised) results

```{r echo = TRUE }
if(!is.null(dv_ls)){
  TTU::write_study_outp_ds(dv_ls,
                           output_format_ls = output_format_ls,
                           path_params_ls = path_params_ls,
                           use_fake_data_1L_lgl = use_fake_data_1L_lgl)
}
```


# Render Scientific Summary

```{r echo = TRUE }
# if(!use_fake_data_1L_lgl){
#   var_nm_change_lup <- tibble::tibble(old_nms_chr = c("PHQ9","GAD7"),
#                                       new_nms_chr = c("PHQ-9", "GAD-7"))
# study_descs_ls <- TTU::make_study_descs_ls(health_utl_nm_1L_chr = "AQol-6D",
#                                            time_btwn_bl_and_fup_1L_chr = "three months",
#                                            predr_ctgs_ls = list(`psychological distress` = c("K6"),
#                                                                 depression =  c("BADS","PHQ9"),
#                                                                 anxiety =  c("GAD7","OASIS","SCARED")))
# spine_of_results_ls <- TTU::make_results_ls_spine(output_data_dir_1L_chr = paths_ls$output_data_dir_1L_chr,
#                                                   var_nm_change_lup = var_nm_change_lup,
#                                                   study_descs_ls = study_descs_ls,
#                                                   nbr_of_digits_1L_int = output_format_ls$manuscript_digits_1L_int)
# cs_ts_ratios_tb = tibble::tibble(predr_nm_chr = c("K6","depression measurements", "anxiety measurements"),
#                                  ratios_chr = c(paste0("about ",
#                                                        round(spine_of_results_ls$mdl_coef_ratios_ls$`psychological distress`,2)),
#                                                 paste0(round(mean(spine_of_results_ls$mdl_coef_ratios_ls$depression),2)),
#                                                 paste0(round(min(spine_of_results_ls$mdl_coef_ratios_ls$anxiety),2)," or over")
#                                  ))
# ctgl_vars_regrouping_ls = list('Primary Diagnosis' = list(anxdpr = list(name_1L_chr = "anxiety/depression",
#                                                                           ctgs_chr = c("Anxiety", "Depression", "Depression and Anxiety"))),
#                                  'Clinical Stage' = list(early = list(name_1L_chr = "early (prior to first episode of a serious mental disorder) clinical stages",
#                                                                       ctgs_chr = c("0-1a","1b"))))
# sig_covars_some_predrs_mdls_tb = tibble::tibble(covars_ls = list(c("No other confounding factor"),
#                                                                                   c("sex at birth"),
#                                                                                                      c("primary diagnosis", "clinical staging","age")),
#                                                                  predrs_mdls_ls = list(c("PHQ-9"), c("K6"),c("anxiety and depression measurements other than PHQ-9")),
#                                                                  sig_thresh_dbl = c(NA_real_,0.01,NA_real_),
#                                                                  assn_strgth_chr = c(NA_character_,NA_character_,"weakly"))
# results_ls <- TTU::make_results_ls(spine_of_results_ls,
#                                    cs_ts_ratios_tb = cs_ts_ratios_tb,
#                                    ctgl_vars_regrouping_ls = ctgl_vars_regrouping_ls,
#                                    sig_covars_some_predrs_mdls_tb = sig_covars_some_predrs_mdls_tb,
#                                    sig_thresh_covars_1L_chr = "0.005")
# saveRDS(results_ls,paste0(paths_ls$output_data_dir_1L_chr,"/results_ls.RDS"))
#   rmarkdown::render("AQoL_VIH/AQoL_VIH.Rmd",
#                     output_format = NULL,
#                     params = list(figures_in_body_lgl = F,
#                                   output_type_1L_chr = "Word",
#                                   results_ls = results_ls,
#                                   tables_in_body_lgl = F),
#                     output_file = paste0("AQoL_VIH", ".docx"),
#                     output_dir = paths_ls$reports_dir_1L_chr)
# }
```

# Purge dataset copies
```{r echo = TRUE }
TTU::write_to_delete_ds_copies(paths_ls)
```

\elandscape
<!---BLOCK_LANDSCAPE_STOP--->
